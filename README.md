
# 0 link del proyecto en streamlit  : https://proyectofinal-3geswd8ggswv3fsu4ekagz.streamlit.app/

```markdown
# Dashboard Retail Inteligente

Este proyecto es un dashboard interactivo construido con **Streamlit** que permite cargar, limpiar y analizar datos de ventas retail. EstÃ¡ diseÃ±ado para responder tres preguntas clave de negocio:

1. **Rentabilidad por categorÃ­a**: Â¿QuÃ© categorÃ­as generan mayor ingreso y cuÃ¡les tienen menor rentabilidad?
2. **Segmentos de clientes**: Â¿QuÃ© segmentos (ubicaciÃ³n, mÃ©todo de pago, categorÃ­a) tienen el ticket promedio mÃ¡s alto y cuÃ¡l es su gasto total?
3. **Patrones temporales**: Â¿Existen patrones semanales, mensuales u horarios en las ventas?

AdemÃ¡s, incluye una secciÃ³n de **insights con IA** mediante la API de Groq (modelo `llama-3.3-70b-versatile`) para generar recomendaciones automÃ¡ticas.

---

## ğŸš€ CaracterÃ­sticas

- **Carga de datos**: Sube archivos CSV con datos de ventas.
- **Limpieza automÃ¡tica**: NormalizaciÃ³n de nombres, manejo de nulos, conversiÃ³n de tipos y feature engineering temporal.
- **ETL y comparativa**: VisualizaciÃ³n del antes/despuÃ©s y exportaciÃ³n de datos limpios.
- **AnÃ¡lisis de negocio**: GrÃ¡ficos interactivos y tablas para cada pregunta.
- **EDA completo**: Distribuciones, correlaciones, series temporales y reporte ejecutivo.
- **KPIs**: MÃ©tricas principales, segmentaciÃ³n y comparativas temporales.
- **IntegraciÃ³n con Groq**: GeneraciÃ³n de insights ejecutivos mediante IA.

---

## ğŸ“‹ Requisitos

- Python 3.9 o superior
- pip (gestor de paquetes)
- (Opcional) Una **API Key de Groq** para usar la secciÃ³n de IA. Puedes obtenerla gratis en [console.groq.com](https://console.groq.com).

---

## ğŸ› ï¸ InstalaciÃ³n y ejecuciÃ³n local

### 1. Clonar el repositorio

```bash
git clone [https://github.com/tu-usuario/dashboard-retail-inteligente.git](https://github.com/julimejia/Proyecto_final.git)
cd dashboard-retail-inteligente
```

### 2. Crear y activar un entorno virtual (recomendado)

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**macOS / Linux:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

**Contenido de `requirements.txt`:**
```
streamlit
pandas
numpy
plotly
requests
```

### 4. Ejecutar la aplicaciÃ³n

```bash
streamlit run app.py
```

La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en tu navegador por defecto (normalmente en `http://localhost:8501`).

---

## ğŸ“ Estructura del proyecto

```
dashboard-retail-inteligente/
â”‚
â”œâ”€â”€ app.py                  # CÃ³digo principal de la aplicaciÃ³n
â”œâ”€â”€ requirements.txt        # Dependencias
â”œâ”€â”€ README.md               # Este archivo      
â””â”€â”€ datasets/    # Carpeta para guardar datos de ejemplo
```

---

## ğŸ”‘ ConfiguraciÃ³n de la API Key de Groq (para IA)

1. ObtÃ©n tu API Key en [console.groq.com](https://console.groq.com).
2. En la barra lateral del dashboard, desplÃ¡zate hasta la secciÃ³n **"ğŸ¤– ConfiguraciÃ³n IA"**.
3. Pega tu clave en el campo de texto (se almacena solo en la sesiÃ³n actual, no se guarda).

Una vez configurada, podrÃ¡s usar la pestaÃ±a **"ğŸ¤– Insights IA"** para generar anÃ¡lisis automÃ¡ticos.

---

Un dataset recomendado para pruebas es el [Retail Store Sales (dirty) de Kaggle](https://www.kaggle.com/datasets/ahmedmohamed2003/retail-store-sales-dirty-for-data-cleaning). El dashboard incluye una limpieza automÃ¡tica adaptada a este formato.

## ğŸ“„ Licencia

Este proyecto fue desarrollado con fines acadÃ©micos para el curso **Fundamentos en Ciencia de Datos** de la **Universidad EAFIT**. Queda bajo la licencia [MIT](LICENSE).

---

## ğŸ‘¨â€ğŸ’» Autores

- **Juan AndrÃ©s Montoya**
- **JuliÃ¡n David MejÃ­a**


ğŸ™ CRÃ‰DITOS Y AGRADECIMIENTOS

Este proyecto no habrÃ­a sido posible sin el valioso trabajo y la inspiraciÃ³n de la comunidad de Kaggle.

- Notebook de referencia: El proceso de limpieza de datos y feature engineering estÃ¡ basado en el enfoque desarrollado en el notebook "Karnyxel is trying to clean the the dataset" (https://www.kaggle.com/code/kashifali68/karnyxel-is-trying-to-clean-the-the-dataset).

- Autor del cÃ³digo: Un agradecimiento especial a Kashif Ali (kashifali68) por publicar y compartir este detallado tutorial.

- InspiraciÃ³n original: Extendemos nuestro reconocimiento a Karnyxel, cuya metodologÃ­a y paso a paso para la limpieza de datos retail fueron seguidos e implementados en este dashboard.

Gracias por compartir conocimiento y contribuir al crecimiento de la comunidad. ğŸš€

Periodo 2026-1

---



